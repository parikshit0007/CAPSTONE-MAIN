{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac014d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7c7c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"CAR DETAILS.csv\")\n",
    "df.head(5)     # Top 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"#### **Checking the datatypes of the columns**\"\"\"\n",
    "\n",
    "# Checking the datatypes of the columns\n",
    "df.dtypes\n",
    "\n",
    "\"\"\"#### **Checking the shape of the dataset**\"\"\"\n",
    "\n",
    "# Checking the shape of the dataset\n",
    "df.shape\n",
    "\n",
    "\"\"\"Number of rows = 4340<br>\n",
    "Number of columns = 8\n",
    "\n",
    "#### **Checking the Column Names**\n",
    "\"\"\"\n",
    "\n",
    "# Checking the Column Names\n",
    "df.columns\n",
    "\n",
    "\"\"\"#### **Checking the Null values (Data Cleaning)**\"\"\"\n",
    "\n",
    "# Checking the Null values\n",
    "df.isnull().sum()\n",
    "\n",
    "\"\"\"There is no null values present in our dataset\n",
    "\n",
    "#### **Checking the duplicate values (Data Cleaning)**\n",
    "\"\"\"\n",
    "\n",
    "df.duplicated().sum()\n",
    "\n",
    "\"\"\"No need to drop duplicate columns because there are columns (fuel type, seller type, owner, transmission) which have less category and same name. so that's why we don't need to drop duplicated rows\n",
    "\n",
    "#### **Description of the columns**\n",
    "\"\"\"\n",
    "\n",
    "# Description of the numerical columns\n",
    "df.describe()\n",
    "\n",
    "# Description of all the columns\n",
    "df.describe(include = \"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cf5747",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"#### **Information about columns**\"\"\"\n",
    "\n",
    "# Short Information of all the columns\n",
    "df.info()\n",
    "\n",
    "\"\"\"#### **Unique Values of Categorical Data**\"\"\"\n",
    "\n",
    "print('Categorical Data: ')\n",
    "\n",
    "print('Fuel unique values: ', df['fuel'].unique())\n",
    "print('Number of unique values: ', df['fuel'].unique().size)\n",
    "\n",
    "print('Seller type unique values: ', df['seller_type'].unique())\n",
    "print('Number of unique values: ', df['seller_type'].unique().size)\n",
    "\n",
    "print('Transmission unique values: ', df['transmission'].unique())\n",
    "print('Number of unique values: ', df['transmission'].unique().size)\n",
    "\n",
    "print('Owner unique values: ', df['owner'].unique())\n",
    "print('Number of unique values: ', df['owner'].unique().size)\n",
    "\n",
    "# Unique number of Cars\n",
    "df[\"name\"].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed916b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"# **Feature Engineering (Data Preprocessing)**\n",
    "\n",
    "#### **Splitting the Car Maker and Car Model from name columns**\n",
    "\"\"\"\n",
    "\n",
    "name = df[\"name\"].str.split(\" \", expand = True)\n",
    "df[\"car_maker\"] = name[0]\n",
    "df[\"car_model\"] = name[1]\n",
    "\n",
    "print(\"Data after splitting car names\")\n",
    "df.head()\n",
    "\n",
    "\"\"\"#### **Adding the current year in dataset**\"\"\"\n",
    "\n",
    "df[\"current_year\"] = 2023\n",
    "\n",
    "df[\"no_of_total_years\"] = df[\"current_year\"]-df[\"year\"]\n",
    "df.drop([\"current_year\"], axis = 1, inplace = True)\n",
    "df.head()\n",
    "\n",
    "df.drop([\"name\"], inplace = True, axis = 1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc3ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"#### **Extract Categorical Columns and Numerical Columns**\"\"\"\n",
    "\n",
    "cat_col = df.select_dtypes(include = \"object\").columns\n",
    "print(\"Categorical Columns:\",cat_col)\n",
    "num_col = df.select_dtypes(exclude = \"object\").columns\n",
    "print(\"Numerical Columns:\",num_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf429c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"# **Uni-Variate EDA**\"\"\"\n",
    "\n",
    "# Value Counts of Categorical Columns\n",
    "a2 = df[\"fuel\"].value_counts()\n",
    "a3 = df[\"seller_type\"].value_counts()\n",
    "a4 = df[\"transmission\"].value_counts()\n",
    "a5 = df[\"owner\"].value_counts()\n",
    "a6 = df[\"car_maker\"].value_counts()\n",
    "a7 = df[\"car_model\"].value_counts()\n",
    "\n",
    "print('Fuel unique values:\\n', a2,\"\\n\")\n",
    "print('Seller type unique values:\\n', a3,\"\\n\")\n",
    "print('Transmission unique values:\\n', a4,\"\\n\")\n",
    "print('Owner unique values:\\n', a5,\"\\n\")\n",
    "print('Car Maker unique values:\\n', a6,\"\\n\")\n",
    "print('Car Model unique values:\\n', a7,\"\\n\")\n",
    "\n",
    "\"\"\"#### **Value Count Plot of Categorical Columns**\"\"\"\n",
    "\n",
    "figure, axis = plt.subplots(3,2, figsize = (12,17))\n",
    "\n",
    "axis[0,0].barh(a5.index, a5.values, color = \"red\", edgecolor = \"Black\")\n",
    "axis[0,0].legend\n",
    "axis[0,0].set_title(\"Owner Count\")\n",
    "\n",
    "axis[0,1].bar(a3.index, a3.values, color = \"orange\", edgecolor = \"Black\")\n",
    "axis[0,1].legend\n",
    "axis[0,1].set_title(\"Seller Type Count\")\n",
    "\n",
    "axis[1,0].bar(a4.index, a4.values, color = \"green\", edgecolor = \"Black\")\n",
    "axis[1,0].legend\n",
    "axis[1,0].set_title(\"Transmission Type Count\")\n",
    "\n",
    "axis[1,1].bar(a2.index, a2.values, color = \"cyan\", edgecolor = \"Black\")\n",
    "axis[1,1].legend\n",
    "axis[1,1].set_title(\"Fuel Type Count\")\n",
    "\n",
    "axis[2,0].barh(a6.index, a6.values, color = \"green\", edgecolor = \"Black\")\n",
    "axis[2,0].legend\n",
    "axis[2,0].set_title(\"Car Maker Type Count\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bc85d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# **Bi-Variate EDA**\n",
    "\n",
    "#### **Scatter plots of numerical columns**\n",
    "\"\"\"\n",
    "\n",
    "# Checking the column names\n",
    "df.columns\n",
    "\n",
    "figure, (ax1, ax2) = plt.subplots(1,2, figsize = (10,3))\n",
    "\n",
    "ax1.scatter(df.year, df[\"selling_price\"], color = \"lightblue\", marker = \"*\")\n",
    "ax1.set_title(\"year vs selling_price\")\n",
    "\n",
    "ax2.scatter(df.year, df[\"km_driven\"], color = \"lightgreen\", marker = \"o\")\n",
    "ax2.set_title(\"year vs km_driven\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\"\"\"#### **Pie Chart of Numerical Columns**\"\"\"\n",
    "\n",
    "# Checking the categorical column names\n",
    "cat_col\n",
    "\n",
    "figure, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize = (10,5))\n",
    "\n",
    "ax1.pie(a2.values, labels = a2.index, autopct = \"%.2f%%\")\n",
    "ax1.legend(bbox_to_anchor = (1,1,0.4,0))\n",
    "ax1.set_title(\"Fuel Count Percentage Distribution\")\n",
    "\n",
    "ax2.pie(a3.values, labels = a3.index, autopct = \"%.2f%%\")\n",
    "ax2.legend(bbox_to_anchor = (1,1,0.4,0))\n",
    "ax2.set_title(\"Seller_type Count Percentage Distribution\")\n",
    "\n",
    "ax3.pie(a4.values, labels = a4.index, autopct = \"%.2f%%\")\n",
    "ax3.legend(bbox_to_anchor = (1,1,0.4,0))\n",
    "ax3.set_title(\"Transmission Count Percentage Distribution\")\n",
    "\n",
    "ax4.pie(a5.values, labels = a5.index, autopct = \"%.2f%%\")\n",
    "ax4.legend(bbox_to_anchor = (1,1,2,0))\n",
    "ax4.set_title(\"Owner Count Percentage Distribution\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71442f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"#### **Boxplot**\"\"\"\n",
    "\n",
    "print(cat_col)\n",
    "print(num_col)\n",
    "\n",
    "plt.figure(figsize = (12,10))\n",
    "sns.boxplot(y = df[\"car_maker\"], x = df.selling_price)\n",
    "plt.ylabel(\"Car Maker\")\n",
    "plt.title(\"Car Maker based on Selling Price - Boxplot\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (12,10))\n",
    "sns.boxplot(x = df.km_driven, y = df[\"car_maker\"])\n",
    "plt.ylabel(\"Car Maker\")\n",
    "plt.title(\"car_maker based on Km driven - Boxplot\")\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (12,10))\n",
    "sns.boxplot(x = df[\"year\"], y = df.fuel)\n",
    "plt.ylabel(\"Fuel Type\")\n",
    "plt.title(\"Fuel based on Year - Boxplot\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (12,10))\n",
    "sns.boxplot(x = df[\"year\"], y = df.seller_type)\n",
    "plt.ylabel(\"Seller Type\")\n",
    "plt.title(\"Seller type based on Year - Boxplot\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\"It can be seen that there are some outliers in our dataset\n",
    "\n",
    "#### **Violin Plot**\n",
    "\"\"\"\n",
    "\n",
    "print(cat_col)\n",
    "print(num_col)\n",
    "\n",
    "plt.figure(figsize = (12,10))\n",
    "sns.violinplot(x = df[\"year\"], y = df.transmission)\n",
    "plt.ylabel(\"Transmission Type\")\n",
    "plt.title(\"Transmission based on Year - Violin plot\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (12,10))\n",
    "sns.violinplot(x = df[\"year\"], y = df.owner)\n",
    "plt.ylabel(\"Ownership\")\n",
    "plt.title(\"Owner based on Year - Violin plot\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\"It can be seen that there are some outliers in our dataset\n",
    "\n",
    "#### **Pair plots of Numerical Columns**\n",
    "\"\"\"\n",
    "\n",
    "df.columns\n",
    "\n",
    "sns.pairplot(data = df, vars = ['year', 'selling_price', 'km_driven', \"no_of_total_years\"])\n",
    "plt.show()\n",
    "\n",
    "\"\"\"#### **Correlation on Heatmap**\"\"\"\n",
    "\n",
    "corr = df.corr()\n",
    "corr\n",
    "\n",
    "sns.heatmap(corr, annot = True, cmap = \"coolwarm\")\n",
    "plt.title(\"Correlation of Numerical columns\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6584be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"It can seen that there is negative or positive correlation between these columns. So, It is okay to be negative or positive correlation but it is not okay to be zero correlation\"\"\"\n",
    "\n",
    "df.drop(\"year\", axis = 1, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7dfbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# **Encoding the Data (Data Preprocessing)**\n",
    "\n",
    "#### **Make a copy of dataframe**\n",
    "\"\"\"\n",
    "\n",
    "# Make a copy of dataframe\n",
    "df1 = df.copy()\n",
    "df1.head()\n",
    "\n",
    "df1.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4280b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#### **Encoding data with get dummies**\"\"\"\n",
    "\n",
    "# Encoding data with get dummies\n",
    "df1 = pd.get_dummies(df1, drop_first=True, columns = [\"car_maker\", \"car_model\"])\n",
    "df1.head()\n",
    "\n",
    "# Checking the shape of the encoded data\n",
    "df1.shape\n",
    "\n",
    "# Checking the datatypes of the encoded data\n",
    "df1.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e63a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"#### **Importing the libraries for encoding**\"\"\"\n",
    "\n",
    "# Importing the libraries for encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\"\"\"#### **Check the columns which we want to encode**\"\"\"\n",
    "\n",
    "# Check the columns which we want to encode\n",
    "cat_col\n",
    "\n",
    "\"\"\"#### **Creating a for loop for Encoding Remaining Columns**\"\"\"\n",
    "\n",
    "# Creating an object of LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Creating a for loop for Encoding multiple columns\n",
    "encoded_columns = ['fuel', 'seller_type', 'transmission', 'owner']\n",
    "\n",
    "for i in encoded_columns:\n",
    "  df1[i] = le.fit_transform(df1[i])\n",
    "\n",
    "\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd0c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"# **Selecting the x** (Dependent variable) **and the y** (Independent variable)\"\"\"\n",
    "\n",
    "x = df1.drop(\"selling_price\", axis = 1)\n",
    "y = df1.selling_price\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\"\"\"# **Splitting the dataset into Training and Testing data**\"\"\"\n",
    "\n",
    "# Importing Libraries for splitting data into Training and Testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = .20, random_state = 0)\n",
    "print(xtrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytrain.shape)\n",
    "print(ytest.shape)\n",
    "\n",
    "# we can check our Test data is correct\n",
    "4340*.25\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad04f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"# **Creating functions to evaluate the Regression Evaluation Metrics, Model Score**<br>\n",
    "\n",
    "*Checking How much my model works efficiently*\n",
    "\n",
    "#### **Importing Libraries**\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Creating functions for evaluating scores\n",
    "def scores(ytest, ypred):\n",
    "  mae = mean_absolute_error(ytest, ypred)\n",
    "  mse = mean_squared_error(ytest, ypred)\n",
    "  rmse = np.sqrt(mean_squared_error(ytest, ypred))\n",
    "  r2 = r2_score(ytest, ypred)\n",
    "  print(\"MAE: \", mae)\n",
    "  print(\"MSE: \", mse)\n",
    "  print(\"RMSE: \", rmse)\n",
    "  print(\"R2 Score: \", r2)\n",
    "\n",
    "def model_score(model):\n",
    "  print(\"Training Score: \", model.score(xtrain, ytrain))\n",
    "  print(\"Testing Score: \", model.score(xtest, ytest))\n",
    "\n",
    "def adjusted_r2_score(ytest, y_pred, n_features):\n",
    "    r_squared = r2_score(ytest, y_pred)\n",
    "    adjusted_r_squared = 1 - (1 - r_squared) * (len(ytest) - 1) / (len(ytest) - n_features - 1)\n",
    "    print(\"Adjusted R2 Score: \", adjusted_r_squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cd7f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"# **Importing the ML Regression Libraries**\"\"\"\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor\n",
    "\n",
    "\"\"\"### **1) Linear Regression**\"\"\"\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(xtrain, ytrain)\n",
    "\n",
    "\"\"\"Checking the Training Score and Testing Score\"\"\"\n",
    "\n",
    "model_score(lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0ea640",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Generate the predictions\"\"\"\n",
    "\n",
    "ypred_lr = lr.predict(xtest)\n",
    "ypred_lr\n",
    "\n",
    "\"\"\"Checking the Scores of our model\"\"\"\n",
    "\n",
    "scores(ytest, ypred_lr)\n",
    "\n",
    "adjusted_r2_score(ytest, ypred_lr, (df1.shape[1]-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d20cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### **2) Ridge Regression**\"\"\"\n",
    "\n",
    "rr = Ridge(alpha=25)\n",
    "rr.fit(xtrain, ytrain)\n",
    "\n",
    "\"\"\"Checking the Training Score and Testing Score\"\"\"\n",
    "\n",
    "model_score(rr)\n",
    "\n",
    "\"\"\"Generate the predictions\"\"\"\n",
    "\n",
    "ypred_rr = rr.predict(xtest)\n",
    "ypred_rr\n",
    "\n",
    "\"\"\"Checking the Scores of our model\"\"\"\n",
    "\n",
    "scores(ytest, ypred_rr)\n",
    "\n",
    "adjusted_r2_score(ytest, ypred_rr, (df1.shape[1]-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9270be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"### **3) Lasso Regression**\"\"\"\n",
    "\n",
    "lar = Lasso(alpha=0.1)\n",
    "lar.fit(xtrain, ytrain)\n",
    "\n",
    "\"\"\"Checking the Training Score and Testing Score\"\"\"\n",
    "\n",
    "model_score(lar)\n",
    "\n",
    "\"\"\"Generate the predictions\"\"\"\n",
    "\n",
    "ypred_lar = lar.predict(xtest)\n",
    "ypred_lar\n",
    "\n",
    "\"\"\"Checking the Scores of our model\"\"\"\n",
    "\n",
    "scores(ytest, ypred_lar)\n",
    "\n",
    "adjusted_r2_score(ytest, ypred_lar, (df1.shape[1]-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18286390",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### **4) KNeighborsRegressor**\"\"\"\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors = 15)\n",
    "knn.fit(xtrain, ytrain)\n",
    "\n",
    "\"\"\"Checking the Training Score and Testing Score\"\"\"\n",
    "\n",
    "model_score(knn)\n",
    "\n",
    "\"\"\"Generate the predictions\"\"\"\n",
    "\n",
    "ypred_knn = knn.predict(xtest)\n",
    "ypred_knn\n",
    "\n",
    "\"\"\"Checking the Scores of our model\"\"\"\n",
    "\n",
    "scores(ytest, ypred_knn)\n",
    "\n",
    "adjusted_r2_score(ytest, ypred_knn, (df1.shape[1]-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436795a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### **5) Decision Tree Regression**\"\"\"\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state = 7, max_depth=4)\n",
    "dtr.fit(xtrain, ytrain)\n",
    "\n",
    "\"\"\"Checking the Training Score and Testing Score\"\"\"\n",
    "\n",
    "model_score(dtr)\n",
    "\n",
    "\"\"\"Generate the predictions\"\"\"\n",
    "\n",
    "ypred_dtr = dtr.predict(xtest)\n",
    "ypred_dtr\n",
    "\n",
    "\"\"\"Checking the Scores of our model\"\"\"\n",
    "\n",
    "scores(ytest, ypred_dtr)\n",
    "\n",
    "adjusted_r2_score(ytest, ypred_dtr, (df1.shape[1]-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4507a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### **6) Bagging Regressor with Decision Tree Regression**\"\"\"\n",
    "\n",
    "bag_dtr = BaggingRegressor(estimator = dtr, n_estimators = 15,\n",
    "                              max_samples = xtrain.shape[0],\n",
    "                            max_features = xtrain.shape[1],\n",
    "                           random_state = 7)\n",
    "bag_dtr.fit(xtrain, ytrain)\n",
    "\n",
    "\"\"\"Checking the Training Score and Testing Score\"\"\"\n",
    "\n",
    "model_score(bag_dtr)\n",
    "\n",
    "\"\"\"Generate the predictions\"\"\"\n",
    "\n",
    "ypred_bag_dtr = bag_dtr.predict(xtest)\n",
    "ypred_bag_dtr\n",
    "\n",
    "\"\"\"Checking the Scores of our model\"\"\"\n",
    "\n",
    "scores(ytest, ypred_bag_dtr)\n",
    "\n",
    "adjusted_r2_score(ytest, ypred_bag_dtr, (df1.shape[1]-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940d8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### **7) Bagging Regressor with Linear Regression**\"\"\"\n",
    "\n",
    "bag_lr = BaggingRegressor(estimator = lr, n_estimators = 15,\n",
    "                              max_samples = xtrain.shape[0],\n",
    "                          max_features = xtrain.shape[1],\n",
    "                          random_state = 7)\n",
    "bag_lr.fit(xtrain, ytrain)\n",
    "\n",
    "\"\"\"Checking the Training Score and Testing Score\"\"\"\n",
    "\n",
    "model_score(bag_lr)\n",
    "\n",
    "\"\"\"Generate the predictions\"\"\"\n",
    "\n",
    "ypred_bag_lr = bag_lr.predict(xtest)\n",
    "ypred_bag_lr\n",
    "\n",
    "\"\"\"Checking the Scores of our model\"\"\"\n",
    "\n",
    "scores(ytest, ypred_bag_lr)\n",
    "\n",
    "adjusted_r2_score(ytest, ypred_bag_lr, (df1.shape[1]-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9e292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# **Checking Errors using Plots**\"\"\"\n",
    "\n",
    "# Creating variables for plotting errors\n",
    "error_lr = [i for i in range(len(ypred_lr))]\n",
    "error_rr = [i for i in range(len(ypred_rr))]\n",
    "error_lar = [i for i in range(len(ypred_lar))]\n",
    "error_knn = [i for i in range(len(ypred_knn))]\n",
    "error_dtr = [i for i in range(len(ypred_dtr))]\n",
    "error_bag_dtr = [i for i in range(len(ypred_bag_dtr))]\n",
    "error_bag_lr = [i for i in range(len(ypred_bag_lr))]\n",
    "\n",
    "figure, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9)) = plt.subplots(3,3, figsize = (15,12))\n",
    "\n",
    "ax1.plot(error_lr, ytest-ypred_lr)\n",
    "ax1.set_title(\"Error in Linear Regression\")\n",
    "\n",
    "ax2.plot(error_rr, ytest-ypred_rr)\n",
    "ax2.set_title(\"Error in Ridge Regression\")\n",
    "\n",
    "ax3.plot(error_lar, ytest-ypred_lar)\n",
    "ax3.set_title(\"Error in Lasso Regression\")\n",
    "\n",
    "ax4.plot(error_knn, ytest-ypred_knn)\n",
    "ax4.set_title(\"Error in KNeighbors Regression\")\n",
    "\n",
    "ax5.plot(error_dtr, ytest-ypred_dtr)\n",
    "ax5.set_title(\"Error in Decision Tree Regression\")\n",
    "\n",
    "ax6.plot(error_bag_dtr, ytest-ypred_bag_dtr)\n",
    "ax6.set_title(\"Error in Bagging Decision Tree Regression\")\n",
    "\n",
    "ax7.plot(error_bag_lr, ytest-ypred_bag_lr)\n",
    "ax7.set_title(\"Error in Bagging Linear Regression\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400d9e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# **Creating Dataframe of Models Score**\"\"\"\n",
    "\n",
    "all_model = {\"Linear Reg\":[mean_absolute_error(ytest, ypred_lr), mean_squared_error(ytest, ypred_lr), np.sqrt(mean_squared_error(ytest, ypred_lr)), r2_score(ytest, ypred_lr), 0.8140642789717978],\n",
    "             \"Ridge Reg\":[mean_absolute_error(ytest, ypred_rr), mean_squared_error(ytest, ypred_rr), np.sqrt(mean_squared_error(ytest, ypred_rr)), r2_score(ytest, ypred_rr), 0.6819590923562783],\n",
    "             \"Lasso Reg\":[mean_absolute_error(ytest, ypred_lar), mean_squared_error(ytest, ypred_lar), np.sqrt(mean_squared_error(ytest, ypred_lar)), r2_score(ytest, ypred_lar), 0.8151527670364602],\n",
    "             \"KNeighbors Reg\":[mean_absolute_error(ytest, ypred_knn), mean_squared_error(ytest, ypred_knn), np.sqrt(mean_squared_error(ytest, ypred_knn)), r2_score(ytest, ypred_knn), 0.3046351810084197],\n",
    "             \"Decision Tree Reg\":[mean_absolute_error(ytest, ypred_dtr), mean_squared_error(ytest, ypred_dtr), np.sqrt(mean_squared_error(ytest, ypred_dtr)), r2_score(ytest, ypred_dtr), 0.5413406772377228],\n",
    "             \"Bagging with Decision Tree Reg\":[mean_absolute_error(ytest, ypred_bag_dtr), mean_squared_error(ytest, ypred_bag_dtr), np.sqrt(mean_squared_error(ytest, ypred_bag_dtr)), r2_score(ytest, ypred_bag_dtr), 0.6277991900261446],\n",
    "             \"Bagging with Linear Reg\":[mean_absolute_error(ytest, ypred_bag_lr), mean_squared_error(ytest, ypred_bag_lr), np.sqrt(mean_squared_error(ytest, ypred_bag_lr)), r2_score(ytest, ypred_bag_lr), 0.8112635600586408]}\n",
    "\n",
    "res = pd.DataFrame(all_model, index = [\"MAE\", \"MSE\", \"RMSE\", \"R2 Score\", \"Adjusted R2 Score\"])\n",
    "res\n",
    "\n",
    "\"\"\"*Lasso Regression is the best model based on Scores*\n",
    "\n",
    "#### **Final model (Lasso Regression) based on Evaluation**\n",
    "\"\"\"\n",
    "\n",
    "model = Lasso(alpha=0.1)\n",
    "model.fit(x, y)\n",
    "\n",
    "\"\"\"#### **Generate predictions for best model**\"\"\"\n",
    "\n",
    "ypred = model.predict(x)\n",
    "ypred\n",
    "\n",
    "\"\"\"#### **Checking Scores for our best model**\"\"\"\n",
    "\n",
    "scores(y, ypred)\n",
    "\n",
    "model_score(model)\n",
    "\n",
    "adjusted_r2_score(y, ypred, (df1.shape[1]-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f0ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# **Importing Pickle Library for Saving and Loading Model**\"\"\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "\"\"\"# **Saving the best model using Pickle**\"\"\"\n",
    "\n",
    "pickle.dump(model,open('best_model.pkl','wb'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a742ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # **Collecting 20 Datapoints randomly from our dataset**\"\"\"\n",
    "\n",
    "df_20 = df1.sample(20)\n",
    "df_20.head()\n",
    "\n",
    "# Saving the Sample Dataset\n",
    "df_20.to_csv(\"sample_dataset.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f5b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#### **Selecting Dependent and Independent Variable for randomly 20 points selecting dataset**\"\"\"\n",
    "\n",
    "x_20 = df_20.drop(\"selling_price\", axis = 1)\n",
    "y_20 = df_20[\"selling_price\"]\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\"\"\"#### **Splitting the data into Training and Testing for randomly 20 points selecting dataset**\"\"\"\n",
    "\n",
    "xtrain_20, xtest_20, ytrain_20, ytest_20 = train_test_split(x, y, test_size = .25)\n",
    "print(xtrain_20.shape)\n",
    "print(ytrain_20.shape)\n",
    "print(xtest_20.shape)\n",
    "print(ytest_20.shape)\n",
    "\n",
    "\"\"\"#### **Loading the best model using Pickle**\"\"\"\n",
    "\n",
    "# Load the saved trained ML model\n",
    "best_model_20 = pickle.load(open(\"/content/best_model.pkl\", \"rb\"))\n",
    "best_model_20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b18f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#### **Generate the Predictions for randomly 20 points selecting dataset**\"\"\"\n",
    "\n",
    "ypred_20 = best_model_20.predict(xtest_20)\n",
    "ypred_20\n",
    "\n",
    "\"\"\"#### **Checking the Scores for randomly 20 points selecting dataset**\"\"\"\n",
    "\n",
    "model_score(best_model_20)\n",
    "\n",
    "scores(ytest_20, ypred_20)\n",
    "\n",
    "adjusted_r2_score(ytest_20, ypred_20, (df_20.shape[1]-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbfb82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# **Making Pipelines**\n",
    "\n",
    "#### **Importing Libraries for Pipelines**\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Extract Categorical Columns\n",
    "categorical_cols = ['fuel', 'seller_type', 'transmission', 'owner', 'car_maker', 'car_model']\n",
    "\n",
    "\"\"\"#### **Splitting data into Training and Testing**\"\"\"\n",
    "\n",
    "X = df.drop(\"selling_price\", axis = 1)\n",
    "Y = df[\"selling_price\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.35, random_state=7)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "# One Hot Encoding\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"OneHotEncoding\", OneHotEncoder(sparse = False, handle_unknown = \"ignore\"), categorical_cols)\n",
    "    ], remainder = \"passthrough\")\n",
    "\n",
    "\"\"\"# **Create Pipelines**\"\"\"\n",
    "\n",
    "# Create Pipeline Object with best fit model\n",
    "lasso = Lasso(alpha = 0.1, max_iter = 1000)\n",
    "pipeline = Pipeline(steps = [(\"Preprocessor\", preprocessor), (\"model\", lasso)], verbose = True)\n",
    "pipeline\n",
    "\n",
    "\"\"\"#### **Train the model**\"\"\"\n",
    "\n",
    "# Fitting the model\n",
    "pipeline.fit(X, Y)\n",
    "\n",
    "\"\"\"#### **Generate the predictions**\"\"\"\n",
    "\n",
    "# Generate the predictions\n",
    "pipe_pred = pipeline.predict(X_test)\n",
    "pipe_pred\n",
    "\n",
    "\"\"\"#### **Checking the score**\"\"\"\n",
    "\n",
    "# Checking the R2 Score\n",
    "r2_score(Y_test, pipe_pred)\n",
    "\n",
    "# Checking the Adjusted R2 Score\n",
    "adjusted_r2_score(Y_test, pipe_pred, (df.shape[1]-1))\n",
    "\n",
    "\"\"\"# **Saving the pipeline model for using in Web App**\"\"\"\n",
    "\n",
    "pickle.dump(pipeline,open('pipeline_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ffeb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
